{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqf1WlZ8wvlCDNH8Biu0/d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stefano-Previti/Diffiner/blob/main/Diffiner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**▶LOAD** **THE** **DATASET**"
      ],
      "metadata": {
        "id": "rCxG88Gwswf2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚓Loading of clean and noisy dataset composed, in both cases, by 28 speakers.\n",
        "\n",
        "⏰**Citation**:Valentini-Botinhao, Cassia. (2017). Noisy speech database for training speech enhancement algorithms and TTS models, 2016 [sound]. University of Edinburgh. School of Informatics. Centre for Speech Technology Research (CSTR). https://doi.org/10.7488/ds/2117."
      ],
      "metadata": {
        "id": "iQgcdVu95dpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Defining paths to your ZIP files on Google Drive\n",
        "zip_clean_train = '/content/drive/My Drive/clean_trainset_28spk_wav.zip'\n",
        "zip_noisy_train = '/content/drive/My Drive/noisy_trainset_28spk_wav.zip'\n",
        "zip_clean_test = '/content/drive/My Drive/clean_testset_wav.zip'\n",
        "zip_noisy_test = '/content/drive/My Drive/noisy_testset_wav.zip'\n",
        "\n",
        "# Defining extraction directories\n",
        "clean_dir = '/content/data/clean_trainset/'\n",
        "noisy_dir = '/content/data/noisy_trainset/'\n",
        "clean_test_dir = '/content/data/clean_testset/'\n",
        "noisy_test_dir = '/content/data/noisy_testset/'\n",
        "\n",
        "# Function to create a directory if it doesn't exist\n",
        "def create_directory(directory):\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "# Creation of directories for extraction\n",
        "create_directory(clean_dir)\n",
        "create_directory(noisy_dir)\n",
        "create_directory(clean_test_dir)\n",
        "create_directory(noisy_test_dir)\n",
        "\n",
        "# Function to extract ZIP files\n",
        "def extract_zip(zip_path, extract_to):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "# Extraction of each ZIP file to its corresponding directory\n",
        "extract_zip(zip_clean_train, clean_dir)\n",
        "extract_zip(zip_noisy_train, noisy_dir)\n",
        "extract_zip(zip_clean_test, clean_test_dir)\n",
        "extract_zip(zip_noisy_test, noisy_test_dir)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zrP-jT3hBrV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f086a62-c57d-4a79-9806-dc58b83f6cf0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Verification of the extraction by listing files in all subdirectories\n",
        "def verify_extraction(directory, num_files_to_check=6):\n",
        "    # Walking through all directories and files\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        print(f'Checking directory: {root}')\n",
        "\n",
        "        # Showing some files (up to num_files_to_check) in this directory\n",
        "        for i, file_name in enumerate(files[:num_files_to_check]):\n",
        "            file_path = os.path.join(root, file_name)\n",
        "            print(f'File {i+1}: {file_path}')\n",
        "\n",
        "# Running the verification functions\n",
        "verify_extraction(clean_dir)\n",
        "verify_extraction(noisy_dir)\n",
        "verify_extraction(clean_test_dir)\n",
        "verify_extraction(noisy_test_dir)\n"
      ],
      "metadata": {
        "id": "EJ5NONmxKUMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚓Creation of a custom dataset object.\n",
        "\n",
        "⏰The choiche is to load only 1/4 of each dataset,after a random shuffling, because of the limitation of the RAM in the colab enviroment."
      ],
      "metadata": {
        "id": "igf_o2YuNJW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing PyTorch and torchaudio\n",
        "!pip install torch torchvision torchaudio\n"
      ],
      "metadata": {
        "id": "Yw_at9a4aSdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import random\n",
        "import torchaudio.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, data_dir):\n",
        "        \"\"\"\n",
        "        Initialization of the dataset with audio files from the specified directory and its subdirectories.\n",
        "        \"\"\"\n",
        "        self.data_dir = data_dir\n",
        "        self.files = self._get_subset_of_audio_files(data_dir)\n",
        "\n",
        "    def _get_subset_of_audio_files(self, directory):\n",
        "        \"\"\"\n",
        "        Recursively collecting a subset (1/4) of all audio files in the directory and its subdirectories.\n",
        "        \"\"\"\n",
        "        audio_files = []\n",
        "        for root, _, files in os.walk(directory):\n",
        "            for file in files:\n",
        "                if file.lower().endswith('.wav'):\n",
        "                    audio_files.append(os.path.join(root, file))\n",
        "\n",
        "        # Shuffling the list of files and taking 1/4 of it\n",
        "        random.shuffle(audio_files)\n",
        "        index = len(audio_files) // 4\n",
        "        return sorted(audio_files[:index])\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Returning the number of audio files.\"\"\"\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Loading and returning the waveform and sample rate for a specific index.\n",
        "        \"\"\"\n",
        "        file_path = os.path.join(self.data_dir, self.files[idx])\n",
        "        if not os.path.isfile(file_path):\n",
        "            raise FileNotFoundError(f\"{file_path} is not a file\")\n",
        "\n",
        "        waveform, sample_rate = torchaudio.load(file_path)\n",
        "        return {'waveform': waveform, 'sample_rate': sample_rate}\n",
        "\n",
        "    def compute_stft(self,waveform):\n",
        "     \"\"\"\n",
        "     Computing the STFT of the waveform using a Hann window and returning a\n",
        "     256x256 tensor with real and imaginary parts as separate channels.\n",
        "     \"\"\"\n",
        "     # Defining th STFT parameters\n",
        "     n_fft = 512\n",
        "     hop_length = 256\n",
        "     win_length = 512\n",
        "     window_fn = torch.hann_window\n",
        "\n",
        "     # Performing STFT\n",
        "     stft_transform = T.Spectrogram(\n",
        "        n_fft=n_fft,\n",
        "        hop_length=hop_length,\n",
        "        win_length=win_length,\n",
        "        window_fn=window_fn,\n",
        "        power=None,\n",
        "     )\n",
        "     stft_spectrogram = stft_transform(waveform)\n",
        "\n",
        "     # Truncation of the DC component\n",
        "     stft_spectrogram = stft_spectrogram[:, 1:, :]\n",
        "\n",
        "     # Extraction of real and imaginary parts\n",
        "     real_part = stft_spectrogram.real\n",
        "     imag_part = stft_spectrogram.imag\n",
        "\n",
        "     # Stacking into a tensor with two channels\n",
        "     two_channel_tensor = torch.stack((real_part, imag_part), dim=1)\n",
        "\n",
        "     # Ensuring the size is 256x256 for the selected time frames and frequency bins\n",
        "     two_channel_tensor = two_channel_tensor[:, :, :256, :256]\n",
        "\n",
        "     return two_channel_tensor\n",
        "\n",
        "# Parameters\n",
        "batch_size = 8\n",
        "\n",
        "# Creation of dataset instances\n",
        "clean_train_dataset = AudioDataset(clean_dir)\n",
        "noisy_train_dataset = AudioDataset(noisy_dir)\n",
        "clean_test_dataset = AudioDataset(clean_test_dir)\n",
        "noisy_test_dataset = AudioDataset(noisy_test_dir)\n",
        "\n",
        "# Print dataset lengths\n",
        "print(\"Number of samples in clean_train_dataset:\", len(clean_train_dataset))\n",
        "print(\"Number of samples in noisy_train_dataset:\", len(noisy_train_dataset))\n",
        "print(\"Number of samples in clean_test_dataset:\", len(clean_test_dataset))\n",
        "print(\"Number of samples in noisy_test_dataset:\", len(noisy_test_dataset))\n",
        "\n",
        "#Custom collate function to handle variable-length audio files in order to avoid the runtime exception of the DataLoader\n",
        "def collate_fn(batch):\n",
        "    waveforms = [item['waveform'] for item in batch]\n",
        "    sample_rates = [item['sample_rate'] for item in batch]\n",
        "    return {'waveform': waveforms, 'sample_rate': sample_rates}\n",
        "\n",
        "# Creation of DataLoader instances\n",
        "clean_train_loader = DataLoader(clean_train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "noisy_train_loader = DataLoader(noisy_train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "clean_test_loader = DataLoader(clean_test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "noisy_test_loader = DataLoader(noisy_test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Debug: Iteration over the first few batches of the clean_train_loader to see what's loaded\n",
        "for batch_idx, batch in enumerate(clean_train_loader):\n",
        "    print(f\"Batch {batch_idx} Loaded\")\n",
        "    for idx in range(len(batch['waveform'])):\n",
        "        waveform = batch['waveform'][idx]\n",
        "        sample_rate = batch['sample_rate'][0]\n",
        "\n",
        "        # Print details for each waveform\n",
        "        print(f\"Sample {idx} - Waveform shape: {waveform.shape}, Sample rate: {sample_rate}\")\n",
        "\n",
        "        if idx >= 1:  # Limit to first few samples for brevity\n",
        "            break\n",
        "    if batch_idx >= 1:  # Limit to first few batches for brevity\n",
        "        break\n",
        "\n"
      ],
      "metadata": {
        "id": "pRX5iclFXAXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "▶**PREPROCESSING OF THE DATA**"
      ],
      "metadata": {
        "id": "ENncKgcYJ85f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚓Here the pre-processing of the data through the computation\n",
        "of the STFT parameters."
      ],
      "metadata": {
        "id": "b71X2ZSvKIsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "def STFT_preprocess_and_save(dataset,data_loader, output_dir):\n",
        "    \"\"\"\n",
        "    Preprocesses the dataset by computing the STFT for each waveform and saving each STFT tensor as a separate file.\n",
        "\n",
        "    Parameters:\n",
        "    - data_loader: A DataLoader object providing batches of audio data.\n",
        "    - output_dir: The directory where the individual STFT tensor files will be saved.\n",
        "    \"\"\"\n",
        "    # Ensuring the destination directory exists\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Initialization of a counter for processed files\n",
        "    file_counter = 0\n",
        "\n",
        "    # Iterate over each batch in the data loader\n",
        "    for batch_index, batch_data in enumerate(data_loader):\n",
        "        # Assuming batch_data is a dictionary containing 'waveform'\n",
        "        waveforms = batch_data['waveform']\n",
        "\n",
        "        # Computing the STFT for each waveform in the batch\n",
        "        for waveform_index, waveform in enumerate(waveforms):\n",
        "            # Computing the STFT for the current waveform\n",
        "            stft_tensor = dataset.compute_stft(waveform)\n",
        "\n",
        "            # Definition of the file name for the current tensor\n",
        "            file_name = f\"stft_tensor_{file_counter}.pt\"\n",
        "            file_path = os.path.join(output_dir, file_name)\n",
        "\n",
        "            # Saving the STFT tensor to a file\n",
        "            torch.save(stft_tensor, file_path)\n",
        "\n",
        "            # Incrementing the file counter\n",
        "            file_counter += 1\n",
        "\n",
        "            # Logging progress every 10 files\n",
        "            if file_counter % 10 == 0:\n",
        "                print(f\"File {file_counter}/{len(data_loader.dataset)} processed and saved to {file_path}\")\n",
        "\n",
        "    print(f\"All tensors have been processed and saved to {output_dir}\")\n",
        "\n",
        "# Directory Paths\n",
        "STFT_clean_preprocessed_dir = '/content/drive/My Drive/STFT_clean_preprocessed/'\n",
        "STFT_clean_test_preprocessed_dir = '/content/drive/My Drive/STFT_clean_test_preprocessed/'\n",
        "STFT_noisy_preprocessed_dir = '/content/drive/My Drive/STFT_noisy_preprocessed/'\n",
        "STFT_noisy_test_preprocessed_dir = '/content/drive/My Drive/STFT_noisy_test_preprocessed/'\n",
        "\n",
        "#Calling the function\n",
        "STFT_preprocess_and_save(clean_train_dataset,clean_train_loader, STFT_clean_preprocessed_dir)\n",
        "STFT_preprocess_and_save(clean_test_dataset,clean_test_loader, STFT_clean_test_preprocessed_dir)\n",
        "STFT_preprocess_and_save(noisy_train_dataset,noisy_train_loader, STFT_noisy_preprocessed_dir)\n",
        "STFT_preprocess_and_save(noisy_test_dataset,noisy_test_loader, STFT_noisy_test_preprocessed_dir)\n"
      ],
      "metadata": {
        "id": "7EB6tnWiKOZi",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "⚓Here the preprocessing for the waveform of each audio in segment lenghts of 16384 sample."
      ],
      "metadata": {
        "id": "PX6TdCowFcXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def waveform_preprocess_and_save(dataloader, output_dir, segment_length=16384):\n",
        "    \"\"\"\n",
        "    Preprocess audio data from a DataLoader and save the preprocessed files.\n",
        "\n",
        "    Args:\n",
        "        dataloader (DataLoader): DataLoader instance that provides audio data.\n",
        "        output_dir (str): Directory to save the preprocessed data.\n",
        "        segment_length (int): Length of audio segments in samples.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    for batch_idx, batch in enumerate(dataloader):\n",
        "        for idx in range(len(batch['waveform'])):\n",
        "            waveform = batch['waveform'][idx]\n",
        "            sample_rate = batch['sample_rate'][0]\n",
        "\n",
        "            # Resampling if necessary\n",
        "            target_sample_rate = 16000\n",
        "            if sample_rate != target_sample_rate:\n",
        "                resample_transform = T.Resample(sample_rate, target_sample_rate)\n",
        "                waveform = resample_transform(waveform)\n",
        "\n",
        "            # Normalizing waveform\n",
        "            waveform = waveform / waveform.abs().max()\n",
        "\n",
        "            # Segmenting and padding the audio\n",
        "            length = waveform.size(1)\n",
        "            if length >= segment_length:\n",
        "                start = random.randint(0, length - segment_length)\n",
        "                segment = waveform[:, start:start + segment_length]\n",
        "            else:\n",
        "                padding = segment_length - length\n",
        "                segment = torch.nn.functional.pad(waveform, (0, padding), 'constant', 0)\n",
        "\n",
        "            # Saving the preprocessed data\n",
        "            file_name = f\"sample_{batch_idx}_{idx}.pt\"\n",
        "            save_path = os.path.join(output_dir, file_name)\n",
        "            torch.save(segment, save_path)\n",
        "\n",
        "            print(f\"Saved preprocessed data: {save_path}\")\n",
        "\n",
        "\n",
        "# Directory Paths\n",
        "waveform_clean_preprocessed_dir = '/content/drive/My Drive/waveform_clean_preprocessed/'\n",
        "waveform_clean_test_preprocessed_dir='/content/drive/My Drive/waveform_clean_test_preprocessed/'\n",
        "waveform_noisy_preprocessed_dir = '/content/drive/My Drive/waveform_noisy_preprocessed/'\n",
        "waveform_noisy_test_preprocessed_dir = '/content/drive/My Drive/waveform_noisy_test_preprocessed/'\n",
        "\n",
        "#Calling the function\n",
        "waveform_preprocess_and_save(clean_train_loader, waveform_clean_preprocessed_dir)\n",
        "waveform_preprocess_and_save(clean_test_loader, waveform_clean_test_preprocessed_dir)\n",
        "waveform_preprocess_and_save(noisy_train_loader, waveform_noisy_preprocessed_dir)\n",
        "waveform_preprocess_and_save(noisy_test_loader, waveform_noisy_test_preprocessed_dir)\n"
      ],
      "metadata": {
        "id": "Jj3T6ForVgAr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}